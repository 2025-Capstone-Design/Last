import cv2
import time
import json
import asyncio
import requests
import numpy as np
from ultralytics import YOLO
import websockets
import winsound
import functools

# ------------------ ì„¤ì • ------------------
CAM_ID = 1
SERVER_URL = "http://127.0.0.1:8000"
WS_URL = "ws://127.0.0.1:8000/ws/data"

# ğŸ”´ 0ë²ˆ ì¹´ë©”ë¼ ê°•ì œ ì§€ì •
WEBCAM_DEVICE_INDEX = 0  
SEND_INTERVAL = 0.05
SHOW_WINDOW = True
DEVICE = 0 

# ğŸ”´ siren.wav íŒŒì¼ ì‚¬ìš© (WAV ë³€í™˜ í•„ìˆ˜)
ALARM_SOUND_FILE = "siren.wav"  
ALARM_COOLDOWN = 1.0 

# âœ… winsoundë¥¼ ì‚¬ìš©í•˜ì—¬ WAV íŒŒì¼ì„ ì¬ìƒí•˜ëŠ” í•¨ìˆ˜
def play_alarm():
    try:
        winsound.PlaySound(ALARM_SOUND_FILE, winsound.SND_FILENAME | winsound.SND_ASYNC)
    except Exception as e:
        print(f"ğŸ”Š ê²½ê³ ìŒ ì¬ìƒ ì‹¤íŒ¨: {e}. 'siren.wav' íŒŒì¼ì´ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

# âœ… ì˜ìƒ ì—…ë¡œë“œ í•¨ìˆ˜
def upload_frame_sync(cam_id, image_bytes):
    try:
        requests.post(
            f"{SERVER_URL}/upload_frame/{cam_id}",
            files={'file': ('frame.jpg', image_bytes, 'image/jpeg')},
            timeout=0.2
        )
    except Exception:
        pass

# âœ… ë‘ ë°•ìŠ¤(ì‚¬ëŒ, í‰ê¸°)ê°€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
def is_overlapping(box1, box2):
    x1_1, y1_1, x2_1, y2_1 = box1
    x1_2, y1_2, x2_2, y2_2 = box2
    if x2_1 < x1_2 or x2_2 < x1_1 or y2_1 < y1_2 or y2_2 < y1_1:
        return False
    return True

async def run_yolo(ws):
    print(f"ğŸš€ YOLO ëª¨ë¸ ë¡œë”© ì¤‘... (GPU) - CAM {CAM_ID}")
    model = YOLO("yolov8n.pt") 

    print(f"ğŸ“· CAM {CAM_ID} ì—°ê²° ì‹œë„ ì¤‘... (Device: {WEBCAM_DEVICE_INDEX})")
    
    cap = cv2.VideoCapture(WEBCAM_DEVICE_INDEX, cv2.CAP_DSHOW)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    time.sleep(1)

    if not cap.isOpened():
        print(f"âŒ ì¹´ë©”ë¼ {WEBCAM_DEVICE_INDEX}ë²ˆì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("âš ï¸ 0ë²ˆ ì‹¤íŒ¨. 1ë²ˆìœ¼ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
        cap.release()
        cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        if not cap.isOpened():
             print("âŒ 1ë²ˆë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
             return

    print(f"âœ… CAM {CAM_ID} ì‹œì‘ (GPU ëª¨ë“œ + ByteTrack)")
    
    last_send = 0.0
    last_alarm_time = 0.0
    dangerous_track_ids = set() 
    
    while True:
        ok, frame = cap.read()
        if not ok:
            print("âš ï¸ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
            break
        
        frame = cv2.flip(frame, 1)

        # ğŸ”´ [ìˆ˜ì •ë¨] YOLO ì¶”ì ì„ ë¹„ë™ê¸° ìŠ¤ë ˆë“œë¡œ ì‹¤í–‰ (í™”ë©´ ì „ì†¡ ë©ˆì¶¤ ë°©ì§€)
        # partialì„ ì‚¬ìš©í•˜ì—¬ ì¸ì ì „ë‹¬ ë¬¸ì œë¥¼ í•´ê²°
        run_track = functools.partial(
            model.track, 
            source=frame, 
            classes=[0, 43, 67], 
            conf=0.3, 
            persist=True, 
            tracker="bytetrack.yaml", 
            verbose=False, 
            device=DEVICE
        )
        results = await asyncio.to_thread(run_track)
        
        people_count = 0
        current_danger_detected = False 
        current_people = [] 
        current_weapons = [] 

        if results and len(results[0].boxes) > 0:
            boxes = results[0].boxes
            for box in boxes:
                cls_id = int(box.cls[0])
                xyxy = box.xyxy[0].cpu().numpy()

                if cls_id == 0:
                    people_count += 1
                    if box.id is not None:
                        track_id = int(box.id[0])
                        current_people.append((xyxy, track_id))
                elif cls_id in [43, 67]:
                    current_weapons.append(xyxy)

        # ìœ„í—˜ ì¸ë¬¼ ë§¤ì¹­ ë¡œì§
        for weapon_box in current_weapons:
            for person_box, person_id in current_people:
                if is_overlapping(weapon_box, person_box):
                    dangerous_track_ids.add(person_id)

        # í™”ë©´ ê·¸ë¦¬ê¸°
        annotated_frame = frame.copy()
        
        for person_box, person_id in current_people:
            x1, y1, x2, y2 = map(int, person_box)
            if person_id in dangerous_track_ids:
                current_danger_detected = True
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 0, 255), 4)
                cv2.putText(annotated_frame, f"DANGER (ID: {person_id})", (x1, y1 - 10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)
            else:
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(annotated_frame, f"Person (ID: {person_id})", (x1, y1 - 10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        for w_box in current_weapons:
             x1, y1, x2, y2 = map(int, w_box)
             cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 255), 2)
             cv2.putText(annotated_frame, "WEAPON", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)

        is_danger = current_danger_detected
        now = time.time()

        if is_danger:
            cv2.rectangle(annotated_frame, (0, 0), (annotated_frame.shape[1], annotated_frame.shape[0]), (0, 0, 255), 10)
            cv2.putText(annotated_frame, "DANGER DETECTED (ALARM!)", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 4)
            if now - last_alarm_time >= ALARM_COOLDOWN:
                play_alarm() 
                last_alarm_time = now

        # ì›¹ì†Œì¼“ ë°ì´í„° ì „ì†¡ ë° ì´ë¯¸ì§€ ì—…ë¡œë“œ
        if now - last_send >= SEND_INTERVAL:
            payload = {
                "cam_id": CAM_ID, 
                "people": people_count, 
                "danger": is_danger, 
                "timestamp": now
            }
            try:
                await ws.send(json.dumps(payload))
                if is_danger: print(f"ğŸš¨ [CAM {CAM_ID}] ìœ„í—˜ ì¸ë¬¼ ì¶”ì  ì¤‘!")
            except:
                break

            frame_resized = cv2.resize(annotated_frame, (640, 360))
            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 60] 
            _, img_encoded = cv2.imencode('.jpg', frame_resized, encode_param)
            
            # ğŸ”´ [ì¤‘ìš”] ì´ë¯¸ì§€ ì—…ë¡œë“œë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            asyncio.create_task(
                asyncio.to_thread(upload_frame_sync, CAM_ID, img_encoded.tobytes())
            )
            last_send = now

        if SHOW_WINDOW:
            cv2.imshow(f"CAM {CAM_ID}", annotated_frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    cap.release()
    cv2.destroyAllWindows()

async def main():
    while True:
        try:
            async with websockets.connect(WS_URL) as ws:
                print(f"ğŸ”Œ CAM {CAM_ID} ì„œë²„ ì—°ê²° ì„±ê³µ")
                await run_yolo(ws)
        except Exception as e:
            print(f"âš ï¸ ì—°ê²° ëŒ€ê¸°ì¤‘... {e}")
            await asyncio.sleep(3)

if __name__ == "__main__":
    asyncio.run(main())